{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection\n",
    "This notebook explains the basic concepts of edge detection using the Numpy and Scipy pckages.\n",
    "\n",
    "\n",
    "Notebook Courtesy: Farhad Kamangar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an edge?\n",
    "* Edge is where change occurs\n",
    "* The changes due to noise are not edges\n",
    "* Edges in real images are not perfectly sharp\n",
    "* Change is measured by gradients\n",
    "* Biggest change is where the gradient has maximum magnitude (Or 2nd derivative is zero)\n",
    "* Edge detection is the process of finding edges in an image\n",
    "* A contour is a curve that passes through neighboring edge points\n",
    "* Edge following is the process of searching the image to determine contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding an edge in one dimensions \n",
    "We know that an edge is where the change occurs. We also know that change is related to the derivative of a signal. if we calculate the derivative of a signal then we can claim that there is an edge at any point that the derivative has a maxima or at any point that the derivative is greater than a prespecified threshold.\n",
    "\n",
    "Let's consider a one dimensional signal and display its derivative.\n",
    "\n",
    "Notice that if the signal is noisy, then the derivative has too many maximas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ipywidgets import interact, fixed, FloatSlider, IntSlider, Label, Checkbox, FloatRangeSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14254af65ee9456ab728adc3deba6c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.2, description='noise_amplitude', max=1.0, step=0.05), Output()), _d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_1d_signal(noise_amplitude=0.1):\n",
    "    kernel=np.array([1,-1])\n",
    "    x=np.linspace(-10,10,100)\n",
    "    y=x.copy()*0\n",
    "    y[int(x.size/2):]=1.0\n",
    "    noise=2*(np.random.rand(*x.shape)-0.5)*noise_amplitude\n",
    "    y=y+noise\n",
    "    derivative=np.convolve(y,kernel,mode='same')\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(8,4)\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    plt.grid(True)\n",
    "    ax1.plot(x,y,color='gray')\n",
    "    plt.ylim(-1,2)\n",
    "    ax1.fill_between(x,y,0,color='#c0f0c0')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.plot(x,derivative,color='gray')\n",
    "    plt.ylim(-1,1)\n",
    "    plt.show()\n",
    "interact(demo_1d_signal,noise_amplitude=FloatSlider(min=0., max=1., step=0.05, value=0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing the effect of noise on edge detection\n",
    "To reduce the effect of noise on edge detection we can convolve the original signal with a smooting kernel such as a Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c534716161b444f6bb74e47cb06801fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.2, description='noise_amplitude', max=1.0, step=0.05), FloatSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib.rcParams['text.usetex'] = True\n",
    "# matplotlib.rcParams['text.latex.unicode'] = True\n",
    "def demo_1d_smoothing(noise_amplitude=0.1,sigma=1):\n",
    "    mean=0\n",
    "    edge_detection_kernel=np.array([1,-1])\n",
    "    x=np.linspace(-10,10,1000)\n",
    "    y=x.copy()*0\n",
    "    y[int(x.size/2):]=0.5\n",
    "    \n",
    "    noise=2*(np.random.rand(*x.shape)-0.5)*noise_amplitude\n",
    "    y=y+noise\n",
    "    gaussian_kernel= (1/np.sqrt(2*np.pi*sigma**2))*np.exp(-((x-mean)**2)/(2*sigma**2))\n",
    "    smooth_signal=np.convolve(y,gaussian_kernel,mode='same')\n",
    "    derivative_of_smooth_signal=np.convolve(smooth_signal,edge_detection_kernel,mode='same')\n",
    "    # Plot the signals\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax1 = fig.add_subplot(4,1,1)\n",
    "    ax1.plot(x,y,color='gray')\n",
    "    ax1.set_ylabel('Original (f)')\n",
    "    plt.grid(True)\n",
    "    plt.ylim(-1,2)\n",
    "    ax2 = fig.add_subplot(4,1,2)\n",
    "    ax2.plot(x,gaussian_kernel,color='gray')\n",
    "    ax2.set_ylabel('Kernel (h)')\n",
    "    plt.grid(True)\n",
    "    ax2.fill_between(x,gaussian_kernel,0,color='#c0f0c0')\n",
    "    plt.ylim(0,2)\n",
    "    ax3 = fig.add_subplot(4,1,3)\n",
    "    ax3.plot(x,smooth_signal,color='gray')\n",
    "    ax3.set_ylabel(r'$h*f$',fontsize=16)\n",
    "    plt.grid(True)\n",
    "    ax3.fill_between(x,smooth_signal,0,color='#c0f0c0')\n",
    "    ax4 = fig.add_subplot(4,1,4)\n",
    "    ax4.plot(x,derivative_of_smooth_signal,color='gray')\n",
    "    ax4.set_ylabel(r'$\\frac{{{\\partial}f}}{{\\partial {x}}}(h*f)$',fontsize=16)\n",
    "    plt.grid(True)\n",
    "    ax4.fill_between(x,derivative_of_smooth_signal,0,color='#c0f0c0')\n",
    "    plt.show()\n",
    "interact(demo_1d_smoothing,noise_amplitude=FloatSlider(min=0., max=1., step=0.05, value=0.2),\n",
    "          sigma=FloatSlider(min=0.1, max=10., step=0.05, value=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the final signal in the above demo is the derivative of the convolution between the original signal and the Gaussian kernel\n",
    "$$\\frac{{{\\partial}f}}{{\\partial {x}}}(h*f)$$ \n",
    "\n",
    "where $h$ is the kernel,  $f$ is the original signal, and $*$ is the convolution\n",
    "\n",
    "This equation can be written as: \n",
    "$$\\frac{{{\\partial}f}}{{\\partial {x}}}(h*f)=(\\frac{{{\\partial}f}}{{\\partial {x}}}h)*f$$\n",
    "\n",
    "This means that instead of convolving the original signal with the Gaussian kernel and then getting the derivative of the resulting signal, we can convolve the origianl signal with the derivative of the Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7833172ab94301ab3beada3177d7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.2, description='noise_amplitude', max=1.0, step=0.05), FloatSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_1d_smoothing_2(noise_amplitude=0.1,sigma=1):\n",
    "    mean=0\n",
    "    edge_detection_kernel=np.array([1,-1])\n",
    "    x=np.linspace(-10,10,100)\n",
    "    y=x.copy()*0\n",
    "    y[int(x.size/2):]=0.5\n",
    "    # Create noise\n",
    "    noise=2*(np.random.rand(*x.shape)-0.5)*noise_amplitude\n",
    "    y=y+noise\n",
    "    gaussian_kernel= (1/np.sqrt(2*np.pi*sigma**2))*np.exp(-((x-mean)**2)/(2*sigma**2))\n",
    "    derivative_of_gaussian=np.convolve(gaussian_kernel,edge_detection_kernel,mode='same')\n",
    "    smooth_signal=np.convolve(y,gaussian_kernel,mode='same')\n",
    "    derivative_of_smooth_signal=np.convolve(y,derivative_of_gaussian,mode='same')\n",
    "    # Plot the signals\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax1 = fig.add_subplot(4,1,1)\n",
    "    ax1.plot(x,y,color='gray')\n",
    "    ax1.set_ylabel('Original (f)')\n",
    "    plt.ylim(-1,2)\n",
    "    plt.grid(True)\n",
    "    ax2 = fig.add_subplot(4,1,2)\n",
    "    ax2.plot(x,gaussian_kernel,color='gray')\n",
    "    ax2.set_ylabel('Kernel (h)')\n",
    "    plt.grid(True)\n",
    "    plt.ylim(-1,2)\n",
    "    ax2.fill_between(x,gaussian_kernel,0,color='#c0f0c0')\n",
    "    ax3 = fig.add_subplot(4,1,3)\n",
    "    ax3.plot(x,derivative_of_gaussian,color='gray')\n",
    "    ax3.set_ylabel(r'$\\frac{{{\\partial}f}}{{\\partial {x}}}(h)$',fontsize=16)\n",
    "    plt.grid(True)  \n",
    "    ax3.fill_between(x,derivative_of_gaussian,0,color='#c0f0c0')\n",
    "    ax4 = fig.add_subplot(4,1,4)\n",
    "    ax4.plot(x,derivative_of_smooth_signal,color='gray')\n",
    "    plt.grid(True)\n",
    "    ax4.fill_between(x,derivative_of_smooth_signal,0,color='#c0f0c0')\n",
    "    ax4.set_ylabel(r'$\\frac{{{\\partial}f}}{{\\partial {x}}}(h)*f$',fontsize=16)\n",
    "    plt.show()\n",
    "_=interact(demo_1d_smoothing_2,noise_amplitude=FloatSlider(min=0., max=1., step=0.05, value=0.2),\n",
    "          sigma=FloatSlider(min=0.1, max=10., step=0.05, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the gradient of an image?\n",
    "Gradient of an image is a vector $\\large \\nabla f = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{\\frac{{\\partial f}}{{\\partial x}}}\\\\\n",
    "{\\frac{{\\partial f}}{{\\partial y}}}\n",
    "\\end{array}} \\right]$\n",
    "\n",
    "Magnitude of gradient at position $ x, y$ tells us how fast the intensity of the image changes in that position $\\large \\left\\| {\\nabla f} \\right\\| = \\sqrt {f_x^2 + f_y^2} $\n",
    "\n",
    "$\\large \\frac{{\\nabla f}}{{\\left\\| {\\nabla f} \\right\\|}}$ is a unit vector in the direction of fastest change.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to calculate gradient on a digital image?\n",
    "We can approximate the gradient on a digital image $f(x,y)$ by subtracting a pixel from it's neighbor. The question is which neighbor. For example the gradient in the x direction at pixel position $(i,j)$ can be calculated either as\n",
    "$$\\large Gx \\approx {\\Delta _x}f\\left( {i,j} \\right) = f\\left( {i + 1,j} \\right) - f\\left( {i,j} \\right)$$ which is called forward difference. Or it may be calculated as:\n",
    "$$\\large Gx \\approx {\\Delta _x}f\\left( {i,j} \\right) = f\\left( {i,j} \\right) - f\\left( {i - 1,j} \\right)$$ which is called backward difference. \n",
    "\n",
    "Notice that we can represent the calculation of the gradient as a linear filter (kernel) operation:\n",
    "\n",
    "$\\large Gx = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{ 1}&-1\n",
    "\\end{array}} \\right]$ \n",
    "\n",
    "The example code below demonstrates the effect of applying the simple gradient kernels in x and y directions\n",
    "\n",
    "$\\large Gx = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{  1}&-1\n",
    "\\end{array}} \\right]$        and              $\\large Gy = \\left[ {\\begin{array}{*{20}{c}}\n",
    "1\\\\\n",
    "{ - 1}\n",
    "\\end{array}} \\right]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convolve\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.interpolation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdemo_gradient_01\u001b[39m(image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,display_absolute\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import convolve\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "def demo_gradient_01(image_size=20,display_absolute=False):\n",
    "    original_image=np.ones((image_size,image_size))\n",
    "    original_image[int(image_size/4):-int(image_size/4),int(image_size/4):-int(image_size/4)]=0\n",
    "    # original_image = data.camera()/255. \n",
    "\n",
    "    horizontal_kernel = np.array([[1],[-1]])\n",
    "    vertical_kernel = np.array([[1.,-1.0]])\n",
    "\n",
    "    # horizontal_kernel = np.array([[ 1.,  2,  1],[ 0,  0,  0],[-1,-2,-1]])\n",
    "    # vertical_kernel = np.array([[ -1.,  0,  1],[ -2,  0,  2],[-1,0,1]])\n",
    "\n",
    "    # Normalize the kernels\n",
    "    kernel_sum=abs(np.sum(horizontal_kernel))\n",
    "    horizontal_kernel= horizontal_kernel/kernel_sum if kernel_sum else horizontal_kernel\n",
    "    kernel_sum=abs(np.sum(vertical_kernel))\n",
    "    vertical_kernel= vertical_kernel/kernel_sum if kernel_sum else vertical_kernel\n",
    "    horizontal_edge_image = scipy.ndimage.convolve(original_image, horizontal_kernel)\n",
    "    vertical_edge_image = scipy.ndimage.convolve(original_image, vertical_kernel)\n",
    "    fig1, axes_array = plt.subplots(1, 3)\n",
    "    fig1.set_size_inches(9,3)\n",
    "#     print(vertical_edge_image)\n",
    "    image_plot = axes_array[0].imshow(original_image ,cmap=plt.cm.gray) # Show the original image\n",
    "    # axes_array[0].axis('off')\n",
    "    axes_array[0].set(title='Original image')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[1].imshow(np.abs(horizontal_edge_image),cmap=plt.cm.gray) # Show absolute value of the filtered image\n",
    "    else:\n",
    "        image_plot = axes_array[1].imshow(horizontal_edge_image,cmap=plt.cm.gray) # Show the filtered image\n",
    "    axes_array[1].axis('off')\n",
    "    axes_array[1].set(title='Horizontal Edges')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[2].imshow(np.abs(vertical_edge_image),cmap=plt.cm.gray) \n",
    "    else:\n",
    "        image_plot = axes_array[2].imshow(vertical_edge_image,cmap=plt.cm.gray) \n",
    "    axes_array[2].axis('off')\n",
    "    axes_array[2].set(title='Vertical Edges')\n",
    "    plt.show()\n",
    "interact(demo_gradient_01,image_size=IntSlider(min=10, max=400., step=10, value=20,description='Image size'),\n",
    "        display_absolute=Checkbox(value=False,description='Display Absolute Vaues',disabled=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging forward and backward gradients of an image\n",
    "We may also calculate the average of forward and backward difference gradients:\n",
    "\n",
    "$$\\large \\frac{{f\\left( {i + 1,j} \\right) - f\\left( {i,j} \\right) + f\\left( {i,j} \\right) - f\\left( {i - 1,j} \\right)}}{2} = 0.5f\\left( {i + 1,j} \\right) - 0.5f\\left( {i - 1,j} \\right)$$\n",
    "\n",
    "Again, we can represent the calculation of the average gradient as a linear filter (kernel) operation:\n",
    "\n",
    " $\\large Gx = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{ -0.5}&0 & 0.5\n",
    "\\end{array}} \\right]$ \n",
    "\n",
    "The code below demonstrates the application of the above kernel in x and y directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "def demo_gradient_02(image_size=20,display_absolute=False):\n",
    "    original_image=np.ones((image_size,image_size))\n",
    "    original_image[int(image_size/4):-int(image_size/4),int(image_size/4):-int(image_size/4)]=0\n",
    "\n",
    "    horizontal_kernel = np.array([[ 1.,  2,  1],[ 0,  0,  0],[-1,-2,-1]])\n",
    "    vertical_kernel = np.array([[ -1.,  0,  1],[ -2,  0,  2],[-1,0,1]])\n",
    "\n",
    "    # Normalize the kernels\n",
    "    kernel_sum=abs(np.sum(horizontal_kernel))\n",
    "    horizontal_kernel= horizontal_kernel/kernel_sum if kernel_sum else horizontal_kernel\n",
    "    kernel_sum=abs(np.sum(vertical_kernel))\n",
    "    vertical_kernel= vertical_kernel/kernel_sum if kernel_sum else vertical_kernel\n",
    "    horizontal_edge_image = scipy.ndimage.convolve(original_image, horizontal_kernel)\n",
    "    vertical_edge_image = scipy.ndimage.convolve(original_image, vertical_kernel)\n",
    "    fig1, axes_array = plt.subplots(1, 3)\n",
    "    fig1.set_size_inches(9,3)\n",
    "    \n",
    "    image_plot = axes_array[0].imshow(original_image ,cmap=plt.cm.gray) # Show the original image\n",
    "    # axes_array[0].axis('off')\n",
    "    axes_array[0].set(title='Original image')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[1].imshow(np.abs(horizontal_edge_image),cmap=plt.cm.gray) # Show absolute value of the filtered image\n",
    "    else:\n",
    "        image_plot = axes_array[1].imshow(horizontal_edge_image,cmap=plt.cm.gray) # Show the filtered image\n",
    "    axes_array[1].axis('off')\n",
    "    axes_array[1].set(title='Horizontal Edges')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[2].imshow(np.abs(vertical_edge_image),cmap=plt.cm.gray) \n",
    "    else:\n",
    "        image_plot = axes_array[2].imshow(vertical_edge_image,cmap=plt.cm.gray) \n",
    "    axes_array[2].axis('off')\n",
    "    axes_array[2].set(title='Vertical Edges')\n",
    "    plt.show()\n",
    "interact(demo_gradient_02,image_size=IntSlider(min=10, max=400., step=10, value=20,description='Image size'),\n",
    "        display_absolute=Checkbox(value=False,description='Display Absolute Vaues',disabled=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in edge detections\n",
    "Generally the edge detection process requires three steps:\n",
    "* **Filtering (noise removal):** Since the calculation of  image gradient is sensitive to noise, a smoothing filter is usually used before calculating the gradient\n",
    "* **Gradient calculation:** Either first or second order gradients are calculated after the noise removal\n",
    "* **Detecting edges:** Once the gradient is calculated, a thresholding, or selection, process is performed to detrmine which points (pixels) are edge points.\n",
    "\n",
    "### Note:\n",
    "Selecting a pixel as an edge pixel does not determine the orientation of the edge or if the continuity of the edge. Additional steps may be required to find the contour which may be passing through a particular pixel. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberts Operator\n",
    "Roberts operator are designed to to respond maximally to gradients running at 45 degrees. The kernels for the roberts operator are:\n",
    "\n",
    "\n",
    "$\\large G = \\left[ {\\begin{array}{*{20}{c}}\n",
    "1&0\\\\\n",
    "0&{ - 1}\n",
    "\\end{array}} \\right]$    and   $\\large G = \\left[ {\\begin{array}{*{20}{c}}\n",
    "0&{ - 1}\\\\\n",
    "1&0\n",
    "\\end{array}} \\right]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "def demo_roberts_operator(image_size=20,rotation_angle=45,display_absolute=False):\n",
    "    original_image=np.ones((image_size,image_size))\n",
    "    original_image[int(image_size/4):-int(image_size/4),int(image_size/4):-int(image_size/4)]=0\n",
    "    original_image=scipy.ndimage.rotate(original_image,rotation_angle)\n",
    "    horizontal_kernel = np.array([[ 1.,0],[ 0,-1.]])\n",
    "    vertical_kernel = np.array([[ 0,-1.],[ 1,0]])\n",
    "\n",
    "    # Normalize the kernels\n",
    "    kernel_sum=abs(np.sum(horizontal_kernel))\n",
    "    horizontal_kernel= horizontal_kernel/kernel_sum if kernel_sum else horizontal_kernel\n",
    "    kernel_sum=abs(np.sum(vertical_kernel))\n",
    "    vertical_kernel= vertical_kernel/kernel_sum if kernel_sum else vertical_kernel\n",
    "\n",
    "    horizontal_edge_image = scipy.ndimage.convolve(original_image, horizontal_kernel)\n",
    "    vertical_edge_image = scipy.ndimage.convolve(original_image, vertical_kernel)\n",
    "    fig1, axes_array = plt.subplots(1, 3)\n",
    "    fig1.set_size_inches(9,3)\n",
    "    image_plot = axes_array[0].imshow(original_image ,cmap=plt.cm.gray) # Show the original image\n",
    "    axes_array[0].axis('off')\n",
    "    axes_array[0].set(title='Original image')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[1].imshow(np.abs(horizontal_edge_image),cmap=plt.cm.gray) # Show the filtered image\n",
    "    else:\n",
    "        image_plot = axes_array[1].imshow(horizontal_edge_image,cmap=plt.cm.gray) # Show the filtered image\n",
    "    axes_array[1].axis('off')\n",
    "    axes_array[1].set(title='-45 Edges')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[2].imshow(np.abs(vertical_edge_image),cmap=plt.cm.gray) # Show the sharpened image\n",
    "    else:\n",
    "        image_plot = axes_array[2].imshow(vertical_edge_image,cmap=plt.cm.gray) # Show the sharpened image\n",
    "    axes_array[2].axis('off')\n",
    "    axes_array[2].set(title='+45 Edges')\n",
    "    plt.show()\n",
    "\n",
    "interact(demo_roberts_operator,image_size=IntSlider(min=10, max=400., step=10, value=20,description='Image size'),\n",
    "         rotation_angle=FloatSlider(min=0.0, max=90., step=5, value=45,description='Angle'),\n",
    "        display_absolute=Checkbox(value=False,description='Display Absolute Vaues',disabled=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel Operator\n",
    "Sobel operators are designed to respond maximally to horizontal and vertical gradients. The kernels for the Sobel operator are:\n",
    "\n",
    "\n",
    "$\\large {G_x} = \\left[ {\\begin{array}{*{20}{c}}\n",
    "{ - 1}&0&1\\\\\n",
    "{ - 2}&0&2\\\\\n",
    "{ - 1}&0&1\n",
    "\\end{array}} \\right]$            and             $\\large {G_y} = \\left[ {\\begin{array}{*{20}{c}}\n",
    "1&2&1\\\\\n",
    "0&0&0\\\\\n",
    "{ - 1}&{ - 2}&{ - 1}\n",
    "\\end{array}} \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "def demo_roberts_operator(image_size=20,rotation_angle=0,display_absolute=False):\n",
    "    original_image=np.ones((image_size,image_size))\n",
    "    original_image[int(image_size/4):-int(image_size/4),int(image_size/4):-int(image_size/4)]=0\n",
    "    original_image=scipy.ndimage.rotate(original_image,rotation_angle)\n",
    "    horizontal_kernel = np.array([[ 1.,  2,  1],[ 0,  0,  0],[-1,-2,-1]])\n",
    "    vertical_kernel = np.array([[ -1.,  0,  1],[ -2,  0,  2],[-1,0,1]])\n",
    "\n",
    "    # Normalize the kernels\n",
    "    kernel_sum=abs(np.sum(horizontal_kernel))\n",
    "    horizontal_kernel= horizontal_kernel/kernel_sum if kernel_sum else horizontal_kernel\n",
    "    kernel_sum=abs(np.sum(vertical_kernel))\n",
    "    vertical_kernel= vertical_kernel/kernel_sum if kernel_sum else vertical_kernel\n",
    "\n",
    "    horizontal_edge_image = scipy.ndimage.convolve(original_image, horizontal_kernel)\n",
    "    vertical_edge_image = scipy.ndimage.convolve(original_image, vertical_kernel)\n",
    "    fig1, axes_array = plt.subplots(1, 3)\n",
    "    fig1.set_size_inches(9,3)\n",
    "    image_plot = axes_array[0].imshow(original_image ,cmap=plt.cm.gray) # Show the original image\n",
    "    axes_array[0].axis('off')\n",
    "    axes_array[0].set(title='Original image')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[1].imshow(np.abs(horizontal_edge_image),cmap=plt.cm.gray) # Show the filtered image\n",
    "    else:\n",
    "        image_plot = axes_array[1].imshow(horizontal_edge_image,cmap=plt.cm.gray) # Show the filtered image\n",
    "    axes_array[1].axis('off')\n",
    "    axes_array[1].set(title='Horizontal Edges')\n",
    "    if display_absolute:\n",
    "        image_plot = axes_array[2].imshow(np.abs(vertical_edge_image),cmap=plt.cm.gray) # Show the sharpened image\n",
    "    else:\n",
    "        image_plot = axes_array[2].imshow(vertical_edge_image,cmap=plt.cm.gray) # Show the sharpened image\n",
    "    axes_array[2].axis('off')\n",
    "    axes_array[2].set(title='Vertical Edges')\n",
    "    plt.show()\n",
    "interact(demo_roberts_operator,image_size=IntSlider(min=10, max=400., step=10, value=20,description='Image size'),\n",
    "         rotation_angle=FloatSlider(min=0.0, max=90., step=5, value=0,description='Angle'),\n",
    "        display_absolute=Checkbox(value=False,description='Display Absolute Vaues',disabled=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the second derivative\n",
    "* Edge points are located at the peaks of the first derivative\n",
    "* An alternative approach is to use the zero crossing of the second derivative. \n",
    "* The **Laplacian** may be used as a second derivative.\n",
    "* The **Laplacian** is symmetric in all directions and is invariant to rotation in the image.\n",
    "\n",
    "The two dimensional equivalent of the second derivative can be written as:\n",
    "$$\\large{\\nabla ^2}f\\left( {x,y} \\right) = \\frac{{{\\partial ^2}f}}{{\\partial {x^2}}} + \\frac{{{\\partial ^2}f}}{{\\partial {y^2}}}$$\n",
    "For digital images the Laplacian at pixel (i,j) is:\n",
    "\n",
    "\n",
    "$$\\large \\begin{array}{c}\n",
    "{\\nabla ^2}f\\left( {i,j} \\right) \\approx f\\left( {i + 1,j} \\right) + f\\left( {i - 1,j} \\right) + f\\left( {i,j + 1} \\right) + \n",
    "f\\left( {i,j - 1} \\right) - 4f\\left( {i,j} \\right)\n",
    "\\end{array}$$\n",
    "\n",
    "\n",
    "Which may be written as a kernel (mask):\n",
    "\n",
    "\n",
    "$$\\large \\left[ {\\begin{array}{*{20}{c}}\n",
    "0&1&0\\\\\n",
    "1&{ - 4}&1\\\\\n",
    "0&1&0\n",
    "\\end{array}} \\right]$$\n",
    "\n",
    "The code below demonstrates the operation of the Laplacian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = data.camera()/255.\n",
    "laplacian_kernel=np.array([[0,1.,0],[1,-4,1],[0,1,0]])\n",
    "processed_image = scipy.ndimage.convolve(original_image, laplacian_kernel)\n",
    "fig1, axes_array = plt.subplots(1, 2)\n",
    "fig1.set_size_inches(8,4)\n",
    "image_plot = axes_array[0].imshow(original_image,cmap=plt.cm.gray) \n",
    "axes_array[0].axis('off')\n",
    "axes_array[0].set(title='Original Image')\n",
    "image_plot = axes_array[1].imshow(processed_image,cmap=plt.cm.gray)\n",
    "axes_array[1].axis('off')\n",
    "axes_array[1].set(title='Laplacian Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the image is noisy then the result of Laplacian filtering will be noisy as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = data.camera()/255.\n",
    "noise=np.random.rand(*original_image.shape)\n",
    "noisy_image=original_image.copy()\n",
    "noisy_image[noise>(1-10*.01)]=1.0\n",
    "laplacian_kernel=np.array([[0,1.,0],[1,-4,1],[0,1,0]])\n",
    "processed_image = scipy.ndimage.convolve(noisy_image, laplacian_kernel)\n",
    "fig1, axes_array = plt.subplots(1, 2)\n",
    "fig1.set_size_inches(8,4)\n",
    "image_plot = axes_array[0].imshow(noisy_image,cmap=plt.cm.gray) \n",
    "axes_array[0].axis('off')\n",
    "axes_array[0].set(title='Noisy Image')\n",
    "image_plot = axes_array[1].imshow(processed_image,cmap=plt.cm.gray)\n",
    "axes_array[1].axis('off')\n",
    "axes_array[1].set(title='Laplacian Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the second derivative creates extraneous zero crossings in the presence of noise, then the image should be smoothed before edge detection. This means that we should smooth the image using a Gaussian kernel and then calculate the second derivative of the resulting image, i.e.  $\\large {\\nabla ^2}(G * f) $\n",
    "\n",
    "However $\\large{\\nabla ^2}(G * f) = ({\\nabla ^2}G) * f$\n",
    "\n",
    "This means that we can convolve the image with the Laplacian of the Gaussian **(LoG)** to get the same effect. The Laplacian of Gaussian can be calculated as:\n",
    "\n",
    "$$\\large {\\nabla ^2}G\\left( x \\right) =  - \\frac{1}{{\\pi {\\sigma ^4}}}\\left( {1 - \\frac{{{x^2}}}{{2{\\sigma ^2}}}} \\right){e^{( - \\frac{{{x^2}}}{{2{\\sigma ^2}}})}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_gaussian_filter_and_display_results(original_image, sigma):\n",
    "    filtered_image=scipy.ndimage.filters.gaussian_laplace(original_image, \n",
    "            sigma=sigma,  output=None, mode='reflect', cval=0.0, truncate=4.0*sigma)\n",
    "    fig1, axes_array = plt.subplots(1, 2)\n",
    "    fig1.set_size_inches(8,4)\n",
    "    image_plot = axes_array[0].imshow(original_image,cmap=plt.cm.gray) \n",
    "    axes_array[0].axis('off')\n",
    "    axes_array[0].set(title='Original Image')\n",
    "    image_plot = axes_array[1].imshow(filtered_image,cmap=plt.cm.gray)\n",
    "    axes_array[1].axis('off')\n",
    "    axes_array[1].set(title='Filtered Image')\n",
    "    plt.show()\n",
    "\n",
    "current_image = data.camera()/255.\n",
    "temp=interact(laplacian_gaussian_filter_and_display_results,original_image=fixed(current_image),\n",
    "         sigma=FloatSlider(min=0.0, max=10, step=0.1,value=1,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoG vs LoG  !!\n",
    "\n",
    "Instead of using Laplacian of Gaussian **LOG**, we can use the Difference of two Gaussian **(DoG)** to approximate the **LoG**.\n",
    "\n",
    "**DoG** is calculated by by subtracting two Gaussians with different sigmas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2d_gaussian_kernel(kernel_size=21, sigma=3):\n",
    "    # Make sure the kernel size is odd\n",
    "    kernel_size=kernel_size if kernel_size%2 else kernel_size+1\n",
    "    temp_image = np.zeros((kernel_size, kernel_size))\n",
    "    # set element at the middle to one\n",
    "    temp_image[int(kernel_size/2), int(kernel_size/2)] = 1\n",
    "    scipy.ndimage.filters.gaussian_filter(temp_image, \n",
    "            sigma=sigma, order=0, output=None, mode='reflect', cval=0.0)\n",
    "    # gaussian-smooth the dirac, resulting in a gaussian filter mask\n",
    "    return scipy.ndimage.filters.gaussian_filter(temp_image, \n",
    "            sigma=sigma, order=0, output=None, mode='reflect', cval=0.0)\n",
    "def demo_dog(original_image,kernel_size=31,sigma_range=[5,10]):\n",
    "    gaussian_kernel_1=create_2d_gaussian_kernel(kernel_size,sigma_range[0])\n",
    "    gaussian_kernel_2=create_2d_gaussian_kernel(kernel_size,sigma_range[1])\n",
    "    difference_of_gaussians=gaussian_kernel_2-gaussian_kernel_1\n",
    "    processed_image = scipy.ndimage.convolve(original_image, difference_of_gaussians)\n",
    "    fig1, axes_array = plt.subplots(1, 2)\n",
    "    fig1.set_size_inches(8,4)\n",
    "    image_plot = axes_array[0].imshow(original_image,cmap=plt.cm.gray) \n",
    "    axes_array[0].axis('off')\n",
    "    axes_array[0].set(title='Original Image')\n",
    "    image_plot = axes_array[1].imshow(processed_image,cmap=plt.cm.gray)\n",
    "    axes_array[1].axis('off')\n",
    "    axes_array[1].set(title='Filtered Image')\n",
    "    plt.show()\n",
    "\n",
    "current_image = data.camera()/255.\n",
    "temp=interact(demo_dog,original_image=fixed(current_image),\n",
    "              kernel_size=IntSlider(min=3, max=101, step=2,value=31,continuous_update=False),\n",
    "            sigma_range=FloatRangeSlider(min=0., max=20., step=0.05,value=[5.0,10.0],continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny edge detector\n",
    "\n",
    "The Canny edge detector is an edge detection algorithm with multiple steps. The steps in the Canny edge detector are listed below: \n",
    "* Smooth the image to remove the noise (Gaussian filter)\n",
    "* Find the gradients of the image\n",
    "* Apply non-maximum suppression\n",
    "* Apply double threshold. Select edge pixels by hysteresis (suppress all edges that are weak and not connected to strong edges).\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "state": {
    "14cc02009280408cbf09efa792caff13": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "1a18edf44319429eb0ecc25d37c00191": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "63e607731e024dd8a0616ec30ab61e06": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "7b9ee4749d66493f99078a93ee8895d7": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "8a44f241befc4163827c4e841a442c0d": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "a216fc1f773245f0a1c3c9ad3b5dbad1": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "df84172056bf4f0ba64527571e7c5768": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "f3ef978cd34e4530b5b267c61b1d86c4": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "f772cc2aeb4849f6be4ba94417784205": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
